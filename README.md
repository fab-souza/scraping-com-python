# scraping-com-python

![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge)

![Badge code size](https://img.shields.io/github/languages/code-size/fab-souza/scraping-com-python)
![Badge de Atualiza√ß√£o](https://img.shields.io/github/last-commit/fab-souza/scraping-com-python)


| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **Web Scraping com Python**
| :label: Tecnologias | python
| :rocket: URL         | [Notebook no Kaggle](https://www.kaggle.com/code/fabianadesouza/web-scraping-com-python)
| :fire: Desafio     | Conte√∫do do curso [Web Scraping com Python](https://cursos.alura.com.br/course/web-scraping-data-science-python)


![capa](https://user-images.githubusercontent.com/67301805/217316982-41393a7a-ac78-49e2-85a5-f53e314d04d5.jpg)

## Sobre o curso üìö

Este foi o √∫ltimo curso da forma√ß√£o Python para Data Science, ministrado pelo instrutor [Rodrigo Dias](https://www.linkedin.com/in/rodrigo-fernando-dias-118181120/), em que aprendi como extrair dados a partir de uma p√°gina web, os principais m√©todos de pesquisa, navega√ß√£o e acesso no HTML, com o aux√≠lio do pacote [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). Neste curso, retiramos os dados a partir de um site fict√≠cio de an√∫ncio de carros, extraindo informa√ß√µes do tipo:
- valor;
- marca/modelo;
- categoria (se √© novo ou usado);
- informa√ß√µes sobre o motor;
- ano de fabrica√ß√£o e quilometragem;
- local que o ve√≠culo se encontra;
- e itens adicionais (por exemplo: c√¢mbio autom√°tico, central multim√≠dia, freio ABS, etc).

![alura motors](https://user-images.githubusercontent.com/67301805/218318139-741afc1c-e7b4-4a90-a36c-79d9107ad659.png)

Iniciamos com a retirada individual de cada item, entendendo como acessar cada *tag*, como usar o m√©todo *find()* para buscar uma *tag*, espec√≠fica ou alguma que seja ‚Äòsua irm√£‚Äô, e como obter os atributos das *tags*. Com essa etapa conclu√≠da, automatizamos a coleta de informa√ß√µes para todos os ve√≠culos presentes naquela p√°gina e criar um dataframe. Ap√≥s extrair esses dados, ampliamos a coleta de dados para todos os ve√≠culos anunciados e recriar o dataframe.

![image](https://user-images.githubusercontent.com/67301805/218325583-5f9edd87-6d16-4287-9973-ac80f95b4a8a.png)


## Minha pr√°tica üë©üèª‚Äçüíª
Para a pr√°tica deste curso, eu decidi retirar informa√ß√µes de uma lista do [Goodreads](https://www.goodreads.com/). A plataforma possui diversas listas de indica√ß√£o de leitura, por exemplo, h√° listas por g√™nero de livro, por ano de lan√ßamento, local em que a hist√≥ria se passa ou caracter√≠stica do(a) personagem principal. 

![pagina_goodreads](https://user-images.githubusercontent.com/67301805/218314254-2cbae394-3426-4afb-aa19-361f10a54dc8.png)

Eu escolhi trabalhar com a lista [Best Books Ever](https://www.goodreads.com/list/show/1.Best_Books_Ever), porque logo nas 20 primeiras posi√ß√µes h√° tanto livros que j√° li ou que quero ler, quanto obras que n√£o conhe√ßo. Al√©m do t√≠tulo e autor do livro, cada item da lista apresenta: 
- a nota m√©dia (*avg rating*);
- a avalia√ß√£o/classifica√ß√£o (*ratings*);
- uma pontua√ß√£o (*score*);
- e quantas pessoas votaram na obra.

Das quatro informa√ß√µes adicionais, eu decidi n√£o trazer as avalia√ß√µes, porque ela n√£o est√° em ordem decrescente ao longo da lista. Por exemplo, o livro **To Kill a Mockingbird** tem uma classifica√ß√£o maior do que **Pride and Prejudice**, mas est√° em uma posi√ß√£o inferior do que a obra de Jane Austen.

![lista_best_books_ever](https://user-images.githubusercontent.com/67301805/218316399-d31f859a-a498-4f80-82cd-87cf3d47e97d.png)

Assim como foi feito no curso, iniciei minha pr√°tica retirando informa√ß√µes sobre o primeiro item da lista, entendendo como acessar e extrair as informa√ß√µes previamente determinadas, em seguida automatizar a coleta e ampliar para os livros presentes na p√°gina. Finalizando com a expans√£o de coleta de dados para as 100 p√°ginas do site, resultando em um dataframe com 10.000 linhas.

![dataframe](https://user-images.githubusercontent.com/67301805/218326752-b288a574-ff53-4b70-97eb-84938c36e896.png)


## Conclus√£o üèÅ

Fazer esta pr√°tica foi uma das que mais me diverti, pois trabalhar com HTML me lembrou de quando comecei a gostar de programa√ß√£o e me livrei da sensa√ß√£o de que programa√ß√£o ‚Äòn√£o era para mim‚Äô, e juntar livros com an√°lise de dados foi a ‚Äòcereja do bolo‚Äô. Em conjunto com este projeto, tamb√©m encerro a revis√£o dos cursos da forma√ß√£o [Python  para Data Science](https://cursos.alura.com.br/formacao-python-data-science-v31955) e darei in√≠cio a revis√£o de outra forma√ß√£o.


## Ferramentas utilizadas üß∞ 
<p> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a>
    <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noreferrer"> <img src="https://beautiful-soup-4.readthedocs.io/en/latest/_images/6.1.jpg" alt="BeautifulSoup" width="40" height="40"/> </a>
    <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a>
    </p>
